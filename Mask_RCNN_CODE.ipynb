{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NgocDuonglab/Intro-to-CS-PROJECT/blob/main/Project_Mask_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OQ9Q_mc_dAo1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mKSX6ZtigBb",
        "outputId": "cb2c0f56-80cc-4f98-ed65-23ce44c004ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cdt1EAl0dApB"
      },
      "outputs": [],
      "source": [
        "images = sorted(os.listdir(\"/content/drive/MyDrive/Project_for_Intro_to_CS/Mask_RCNN/dataset/train\"))\n",
        "masks = sorted(os.listdir(\"/content/drive/MyDrive/Project_for_Intro_to_CS/Mask_RCNN/dataset/mask\"))\n",
        "# images = sorted(os.listdir(\"/content/drive/MyDrive/Draft/Images\"))\n",
        "# masks = sorted(os.listdir(\"/content/drive/MyDrive/Draft/mask\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8ruaXV_VdApD"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "img = Image.open(\"/content/drive/MyDrive/Project_for_Intro_to_CS/Mask_RCNN/dataset/train/\" + images[idx]).convert(\"RGB\")\n",
        "mask = Image.open(\"/content/drive/MyDrive/Project_for_Intro_to_CS/Mask_RCNN/dataset/mask/\" + masks[idx])\n",
        "# img = Image.open(\"/content/drive/MyDrive/Draft/Images/\" + images[idx]).convert(\"RGB\")\n",
        "# mask = Image.open(\"/content/drive/MyDrive/Draft/mask/\" + masks[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bV2KjPrmdApN",
        "outputId": "f0e70ae6-4f5d-4b4a-a5f0-16e5bc80b333",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0, 128], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "np.unique(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XoeOKMTNdApS"
      },
      "outputs": [],
      "source": [
        "class CustDat(torch.utils.data.Dataset):\n",
        "    def __init__(self , images , masks):\n",
        "        self.imgs = images\n",
        "        self.masks = masks\n",
        "\n",
        "    def __getitem__(self , idx):\n",
        "        img = Image.open(\"/content/drive/MyDrive/Project_for_Intro_to_CS/Mask_RCNN/dataset/train/\" + self.imgs[idx]).convert(\"RGB\")\n",
        "        mask = Image.open(\"/content/drive/MyDrive/Project_for_Intro_to_CS/Mask_RCNN/dataset/mask/\" + self.masks[idx]).convert(\"L\")\n",
        "        # img = Image.open(\"/content/drive/MyDrive/Draft/Images/\" + self.imgs[idx]).convert(\"RGB\")\n",
        "        # mask = Image.open(\"/content/drive/MyDrive/Draft/mask/\" + self.masks[idx]).convert(\"L\")\n",
        "        mask = np.array(mask)\n",
        "        obj_ids = np.unique(mask)\n",
        "        # obj_ids = obj_ids[1:]  # train luôn background nha (k báo lỗi nhưng train sẽ thiếu class)\n",
        "        num_objs = len(obj_ids)\n",
        "        masks = np.zeros((num_objs , mask.shape[0] , mask.shape[1]))\n",
        "        for i in range(num_objs):\n",
        "            # masks[i][mask == i+1] = True  # cách này chỉ đúng nếu label đánh theo thứ tự\n",
        "            masks[i] = (mask == obj_ids[i])\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            pos = np.where(masks[i])\n",
        "            xmin = np.min(pos[1])\n",
        "            xmax = np.max(pos[1])\n",
        "            ymin = np.min(pos[0])\n",
        "            ymax = np.max(pos[0])\n",
        "            boxes.append([xmin , ymin , xmax , ymax])\n",
        "        boxes = torch.as_tensor(boxes , dtype = torch.float32)\n",
        "        labels = torch.ones((num_objs,) , dtype = torch.int64)\n",
        "        masks = torch.as_tensor(masks , dtype = torch.uint8)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"masks\"] = masks\n",
        "        return T.ToTensor()(img), target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2cvV4MFodApP"
      },
      "outputs": [],
      "source": [
        "binary_mask_1 = np.array(mask) == 1\n",
        "binary_mask_2 = np.array(mask) == 2\n",
        "\n",
        "img_1 = Image.fromarray((binary_mask_1 * 255).astype(np.uint8))\n",
        "img_2 = Image.fromarray((binary_mask_2 * 255).astype(np.uint8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_NKZDmyMdApV"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn()\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features , 2)\n",
        "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "hidden_layer = 256\n",
        "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask , hidden_layer , 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nCF3QluOdApX"
      },
      "outputs": [],
      "source": [
        "transform = T.ToTensor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TsHvC9xidApY"
      },
      "outputs": [],
      "source": [
        "def custom_collate(data):\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cojhLWBDdApY"
      },
      "outputs": [],
      "source": [
        "images = sorted(os.listdir(\"/content/drive/MyDrive/Project_for_Intro_to_CS/Mask_RCNN/dataset/train\"))\n",
        "masks = sorted(os.listdir(\"/content/drive/MyDrive/Project_for_Intro_to_CS/Mask_RCNN/dataset/mask\"))\n",
        "# images = sorted(os.listdir(\"/content/drive/MyDrive/Draft/Images\"))\n",
        "# masks = sorted(os.listdir(\"/content/drive/MyDrive/Draft/mask\"))\n",
        "num = int(0.9 * len(images))\n",
        "num = num if num % 2 == 0 else num + 1\n",
        "train_imgs_inds = np.random.choice(range(len(images)) , num , replace = False)\n",
        "val_imgs_inds = np.setdiff1d(range(len(images)) , train_imgs_inds)\n",
        "train_imgs = np.array(images)[train_imgs_inds]\n",
        "val_imgs = np.array(images)[val_imgs_inds]\n",
        "train_masks = np.array(masks)[train_imgs_inds]\n",
        "val_masks = np.array(masks)[val_imgs_inds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s_q-3xVPdApZ"
      },
      "outputs": [],
      "source": [
        "train_dl = torch.utils.data.DataLoader(CustDat(train_imgs , train_masks) ,\n",
        "                                 batch_size = 2 ,\n",
        "                                 shuffle = True ,\n",
        "                                 collate_fn = custom_collate ,\n",
        "                                 num_workers = 1 ,\n",
        "                                 pin_memory = True if torch.cuda.is_available() else False)\n",
        "val_dl = torch.utils.data.DataLoader(CustDat(val_imgs , val_masks) ,\n",
        "                                 batch_size = 2 ,\n",
        "                                 shuffle = True ,\n",
        "                                 collate_fn = custom_collate ,\n",
        "                                 num_workers = 1 ,\n",
        "                                 pin_memory = True if torch.cuda.is_available() else False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dZEPXmo3dApZ",
        "outputId": "2e0f7af9-4660-453c-ffe7-ba1202638f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "m9R6PxFRdApa"
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CQvvtGeddApb"
      },
      "outputs": [],
      "source": [
        "params = [p for p in model.parameters() if p.requires_grad]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "U89Pd31XdApb"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7GXTV5qdApc"
      },
      "outputs": [],
      "source": [
        "all_train_losses = []\n",
        "all_val_losses = []\n",
        "flag = False\n",
        "\n",
        "for epoch in range(30):\n",
        "  train_epoch_loss = 0\n",
        "  val_epoch_loss = 0\n",
        "  model.train()\n",
        "  for i , dt in enumerate(train_dl):\n",
        "    imgs = [dt[0][0].to(device) , dt[1][0].to(device)]\n",
        "    targ = [dt[0][1] , dt[1][1]]\n",
        "    # imgs = dt[0]\n",
        "    # targ = dt[1]\n",
        "    targets = [{k: v.to(device) for k, v in t.items()} for t in targ]\n",
        "    loss = model(imgs , targets)\n",
        "    if not flag:\n",
        "      print(loss)\n",
        "      flag = True\n",
        "      losses = sum([l for l in loss.values()])\n",
        "      train_epoch_loss += losses.cpu().detach().numpy()\n",
        "      optimizer.zero_grad()\n",
        "      losses.backward()\n",
        "      optimizer.step()\n",
        "      all_train_losses.append(train_epoch_loss)\n",
        "  with torch.no_grad():\n",
        "    for j , dt in enumerate(val_dl):\n",
        "      imgs = [dt[0][0].to(device) , dt[1][0].to(device)]\n",
        "      targ = [dt[0][1] , dt[1][1]]\n",
        "      targets = [{k: v.to(device) for k, v in t.items()} for t in targ]\n",
        "      loss = model(imgs , targets)\n",
        "      losses = sum([l for l in loss.values()])\n",
        "      val_epoch_loss += losses.cpu().detach().numpy()\n",
        "      all_val_losses.append(val_epoch_loss)\n",
        "  print(epoch , \"  \" , train_epoch_loss , \"  \" , val_epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "id": "eYZWcYTpkz7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses"
      ],
      "metadata": {
        "id": "pmtiHNFDk13a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOR-1YaudApe"
      },
      "outputs": [],
      "source": [
        "plt.plot(all_val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_429RvhkdApg"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "img = Image.open(\"/content/drive/MyDrive/Project_for_Intro_to_CS/Mask_RCNN/dataset/train/1.jpg\")\n",
        "transform = T.ToTensor()\n",
        "ig = transform(img)\n",
        "with torch.no_grad():\n",
        "    pred = model([ig.to(device)])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
